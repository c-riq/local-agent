{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e501686f-323f-4b87-8f9c-8ba89133078b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -U langchain_community langchain-openai langchain-experimental langchain langgraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef4fb67-113a-4b88-9f93-7e3a95cee035",
   "metadata": {},
   "source": [
    "### LLM\n",
    "\n",
    "We'll use the Mistral API and `Codestral` instruct model, which support tool use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "982e4609-86e4-4934-828f-e03d89c20393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa22a2b-4a6d-4ac4-ae00-36449e926aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.globals import set_debug\n",
    "\n",
    "set_debug(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a3dca9-4485-4ae5-aa87-cd1f02bad8b9",
   "metadata": {},
   "source": [
    "## Code Generation\n",
    "\n",
    "Test with structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a188c8ca-c053-4e6d-b7af-38a3b6b371c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select LLM\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "llm = OllamaFunctions(model=\"codellama\", format=\"json\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4191c0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cfb3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt \n",
    "test_gen_prompt = PromptTemplate.from_template((\n",
    "            \"\"\"You are a coding assistant writing test which throw an exception for every failed test for Test Driven Development. Ensure any code you provide can be executed with all required imports and variables \\n\n",
    "            defined. Structure your answer: 1) a prefix describing the test, 2) the imports, 3) the functioning test code block.\n",
    "            \\n Human: {question}\n",
    "            AI: \"\"\"))\n",
    "\n",
    "code_gen_prompt = PromptTemplate.from_template((\n",
    "            \"\"\"You are a coding assistant. Ensure any code you provide can be executed with all required imports and variables \\n\n",
    "            defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the functioning code block.\n",
    "            \\n Human: {question}. Include the following test code below the implementation: {tests}\n",
    "            AI: \"\"\"))\n",
    "\n",
    "combined_prompt = PromptTemplate.from_template((\n",
    "            \"\"\"You are a coding assistant. Ensure any code or test you provide can be executed with all required imports and variables \\n\n",
    "            defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the tests to check corectness of your solution and invocation of these tests, 4) the functioning code block.\n",
    "            \\n Human: {question}\n",
    "            AI: \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c3efe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data model\n",
    "class test_code(BaseModel):\n",
    "    \"\"\"Code output\"\"\"\n",
    "\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block not including import statements\")\n",
    "    test: str = Field(description=\"Test code block not including import statements\")\n",
    "    description = \"Schema for code solutions to questions about LCEL.\"\n",
    "\n",
    "structured_llm = llm.with_structured_output(test_code)\n",
    "#test_gen_chain = test_gen_prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccfeaeb3-796e-4710-a526-fe5c605ba268",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code_gen_chain = code_gen_prompt | structured_llm\n",
    "combined_chain = combined_prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fc0290d-5a04-4514-8664-91f9dbf2da7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Write a function for fibonacci.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "973281bd-e74b-4386-98c6-210af5e31982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Write a function for fibonacci.\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"Write a function for fibonacci.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a coding assistant. Ensure any code or test you provide can be executed with all required imports and variables \\n\\n            defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the tests to check corectness of your solution and invocation of these tests, 4) the functioning code block.\\n            \\n Human: Write a function for fibonacci.\\n            AI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:RunnableSequence > llm:OllamaFunctions] [6.87s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-048cc7ec-6ea5-4d6c-8790-aee7d295de51-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"test_code\",\n",
      "                \"args\": {\n",
      "                  \"prefix\": \"Write a function to calculate Fibonacci numbers.\",\n",
      "                  \"imports\": \"\",\n",
      "                  \"code\": \"def fib(n):\\n    if n <= 1:\\n        return n\\n    else:\\n        return fib(n-1) + fib(n-2)\",\n",
      "                  \"test\": \"assert fib(0) == 0\\nassert fib(1) == 1\\nassert fib(2) == 1\\nassert fib(3) == 2\\nassert fib(4) == 3\\nassert fib(5) == 5\\nassert fib(6) == 8\"\n",
      "                },\n",
      "                \"id\": \"call_58e900f1c272448987234f105fb97627\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > chain:parse_response] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"{\\\"prefix\\\": \\\"Write a function to calculate Fibonacci numbers.\\\", \\\"imports\\\": \\\"\\\", \\\"code\\\": \\\"def fib(n):\\\\n    if n <= 1:\\\\n        return n\\\\n    else:\\\\n        return fib(n-1) + fib(n-2)\\\", \\\"test\\\": \\\"assert fib(0) == 0\\\\nassert fib(1) == 1\\\\nassert fib(2) == 1\\\\nassert fib(3) == 2\\\\nassert fib(4) == 3\\\\nassert fib(5) == 5\\\\nassert fib(6) == 8\\\"}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"{\\\"prefix\\\": \\\"Write a function to calculate Fibonacci numbers.\\\", \\\"imports\\\": \\\"\\\", \\\"code\\\": \\\"def fib(n):\\\\n    if n <= 1:\\\\n        return n\\\\n    else:\\\\n        return fib(n-1) + fib(n-2)\\\", \\\"test\\\": \\\"assert fib(0) == 0\\\\nassert fib(1) == 1\\\\nassert fib(2) == 1\\\\nassert fib(3) == 2\\\\nassert fib(4) == 3\\\\nassert fib(5) == 5\\\\nassert fib(6) == 8\\\"}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence > parser:PydanticOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:RunnableSequence] [6.87s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\n",
      "def fib(n):\n",
      "    if n <= 1:\n",
      "        return n\n",
      "    else:\n",
      "        return fib(n-1) + fib(n-2)\n",
      "assert fib(0) == 0\n",
      "assert fib(1) == 1\n",
      "assert fib(2) == 1\n",
      "assert fib(3) == 2\n",
      "assert fib(4) == 3\n",
      "assert fib(5) == 5\n",
      "assert fib(6) == 8\n",
      "Schema for code solutions to questions about LCEL.\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "llm_response = combined_chain.invoke(question)\n",
    "print(llm_response.imports)\n",
    "print(llm_response.code)\n",
    "print(llm_response.test)\n",
    "print(llm_response.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54fe1169-c95a-40ba-a337-68da209f4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(code_gen_chain.invoke({\"question\":question, \"tests\": tests.test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "183d77b8-f180-4815-b39f-8ef507ec0534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing import Dict, TypedDict, List\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        error : Binary flag for control flow to indicate whether test error was tripped\n",
    "        messages : With user question, error messages, reasoning\n",
    "        generation : Code solution\n",
    "        iterations : Number of tries\n",
    "    \"\"\"\n",
    "\n",
    "    error: str\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    generation: str\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55043d78-c012-4280-bc8b-259f04a29cb4",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "14bc89d1-3ca6-4847-a048-1803e0e4600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "### Parameters\n",
    "max_iterations = 3\n",
    "\n",
    "### Nodes\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "\n",
    "    # Solution\n",
    "    code_solution = combined_chain.invoke(messages)\n",
    "    messages += [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            f\"Here is my attempt to solve the problem: {code_solution.prefix} \\n Imports: {code_solution.imports} \\n Test: {code_solution.test} \\n Code: {code_solution.code}\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Increment\n",
    "    iterations = iterations + 1\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "def code_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECKING CODE---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    # Get solution components\n",
    "    prefix = code_solution.prefix\n",
    "    imports = code_solution.imports\n",
    "    test = code_solution.test\n",
    "    code = code_solution.code\n",
    "\n",
    "    # Check imports\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the import test. Here is the error: {e}. Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # Check execution\n",
    "    try:\n",
    "        combined_code = f\"{imports}\\n{code}\\n{test}\"\n",
    "        # Use a shared scope for exec\n",
    "        global_scope = {}\n",
    "        exec(combined_code, global_scope)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the code execution test or unit test: {e}) Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # No errors\n",
    "    print(\"---NO CODE TEST FAILURES---\")\n",
    "    return {\n",
    "        \"generation\": code_solution,\n",
    "        \"messages\": messages,\n",
    "        \"iterations\": iterations,\n",
    "        \"error\": \"no\",\n",
    "    }\n",
    "\n",
    "### Conditional edges\n",
    "\n",
    "def decide_to_finish(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations == max_iterations:\n",
    "        print(\"---DECISION: FINISH---\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        return \"generate\"\n",
    "\n",
    "### Utilities\n",
    "\n",
    "import uuid \n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(f\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2dff2209-44c7-4e2c-b607-ba6675f9e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.graph import END, StateGraph\n",
    "\n",
    "builder = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "builder.add_node(\"generate\", generate)  # generation solution\n",
    "builder.add_node(\"check_code\", code_check)  # check code\n",
    "\n",
    "# Build graph\n",
    "builder.set_entry_point(\"generate\")\n",
    "builder.add_edge(\"generate\", \"check_code\")\n",
    "builder.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4bb21cd-af20-4d4d-89ff-384db034b7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "993ba306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.11/site-packages (10.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "242aa2f0-2c31-462f-a958-ff9ae0cf7c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"user\",\n",
      "      \"Write a Python program that prints 'Hello, World!' to the console.\"\n",
      "    ]\n",
      "  ],\n",
      "  \"iterations\": 0\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"user\",\n",
      "      \"Write a Python program that prints 'Hello, World!' to the console.\"\n",
      "    ]\n",
      "  ],\n",
      "  \"iterations\": 0\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"user\",\n",
      "      \"Write a Python program that prints 'Hello, World!' to the console.\"\n",
      "    ]\n",
      "  ],\n",
      "  \"iterations\": 0\n",
      "}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Write a Python program that prints 'Hello, World!' to the console.\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a coding assistant. Ensure any code or test you provide can be executed with all required imports and variables \\n\\n            defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the tests to check corectness of your solution and invocation of these tests, 4) the functioning code block.\\n            \\n Human: [HumanMessage(content=\\\"Write a Python program that prints 'Hello, World!' to the console.\\\", id='6f119c70-dfa5-42fd-8010-46b1bc029813')]\\n            AI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:OllamaFunctions] [3.42s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-2dfb7e61-1e4b-4cf6-89a5-995ed2166206-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"test_code\",\n",
      "                \"args\": {\n",
      "                  \"prefix\": \"Print 'Hello, World!' to the console.\",\n",
      "                  \"imports\": \"\",\n",
      "                  \"code\": \"print('Hello, World!')\",\n",
      "                  \"test\": \"\"\n",
      "                },\n",
      "                \"id\": \"call_a92fe7cfbc8b4b758e7cd98bef322b14\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > chain:parse_response] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > chain:parse_response] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"{\\\"prefix\\\": \\\"Print 'Hello, World!' to the console.\\\", \\\"imports\\\": \\\"\\\", \\\"code\\\": \\\"print('Hello, World!')\\\", \\\"test\\\": \\\"\\\"}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"{\\\"prefix\\\": \\\"Print 'Hello, World!' to the console.\\\", \\\"imports\\\": \\\"\\\", \\\"code\\\": \\\"print('Hello, World!')\\\", \\\"test\\\": \\\"\\\"}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:PydanticOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [3.42s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,error,messages,generation,iterations>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,error,messages,generation,iterations>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [3.43s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is my attempt to solve the problem: Print 'Hello, World!' to the console. \n",
      " Imports:  \n",
      " Test:  \n",
      " Code: print('Hello, World!')\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECKING CODE---\n",
      "Hello, World!\n",
      "---NO CODE TEST FAILURES---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<check_code,error,messages,generation,iterations>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<check_code,error,messages,generation,iterations>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:decide_to_finish] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---DECISION: FINISH---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:decide_to_finish] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"end\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph] [3.43s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "test_code(prefix=\"Print 'Hello, World!' to the console.\", imports='', code=\"print('Hello, World!')\", test='', description='Schema for code solutions to questions about LCEL.')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "_printed = set()\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "question = \"Write a Python program that prints 'Hello, World!' to the console.\"\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", question)], \"iterations\": 0}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    _print_event(event, _printed)\n",
    "\n",
    "event['generation']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6924e707-5970-4254-a748-fa75628916f2",
   "metadata": {},
   "source": [
    "`Trace:`\n",
    "\n",
    "https://smith.langchain.com/public/53bcdaab-e3c5-4423-9908-c44595325c38/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2bb883df-540b-46ab-9415-fe27db68456f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"user\",\n",
      "      \"I want to vectorize a function\\n\\n        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\n        for i, val1 in enumerate(rows):\\n            for j, val2 in enumerate(cols):\\n                for j, val3 in enumerate(ch):\\n                    # Assuming you want to store the pair as tuples in the matrix\\n                    frame[i, j, k] = image[val1, val2, val3]\\n\\n        out.write(np.array(frame))\\n\\nwith a simple numpy function without using for loop\"\n",
      "    ]\n",
      "  ],\n",
      "  \"iterations\": 0\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"user\",\n",
      "      \"I want to vectorize a function\\n\\n        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\n        for i, val1 in enumerate(rows):\\n            for j, val2 in enumerate(cols):\\n                for j, val3 in enumerate(ch):\\n                    # Assuming you want to store the pair as tuples in the matrix\\n                    frame[i, j, k] = image[val1, val2, val3]\\n\\n        out.write(np.array(frame))\\n\\nwith a simple numpy function without using for loop\"\n",
      "    ]\n",
      "  ],\n",
      "  \"iterations\": 0\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:__start__] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"messages\": [\n",
      "    [\n",
      "      \"user\",\n",
      "      \"I want to vectorize a function\\n\\n        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\n        for i, val1 in enumerate(rows):\\n            for j, val2 in enumerate(cols):\\n                for j, val3 in enumerate(ch):\\n                    # Assuming you want to store the pair as tuples in the matrix\\n                    frame[i, j, k] = image[val1, val2, val3]\\n\\n        out.write(np.array(frame))\\n\\nwith a simple numpy function without using for loop\"\n",
      "    ]\n",
      "  ],\n",
      "  \"iterations\": 0\n",
      "}\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I want to vectorize a function\n",
      "\n",
      "        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\n",
      "        for i, val1 in enumerate(rows):\n",
      "            for j, val2 in enumerate(cols):\n",
      "                for j, val3 in enumerate(ch):\n",
      "                    # Assuming you want to store the pair as tuples in the matrix\n",
      "                    frame[i, j, k] = image[val1, val2, val3]\n",
      "\n",
      "        out.write(np.array(frame))\n",
      "\n",
      "with a simple numpy function without using for loop\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a coding assistant. Ensure any code or test you provide can be executed with all required imports and variables \\n\\n            defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the tests to check corectness of your solution and invocation of these tests, 4) the functioning code block.\\n            \\n Human: [HumanMessage(content='I want to vectorize a function\\\\n\\\\n        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n        for i, val1 in enumerate(rows):\\\\n            for j, val2 in enumerate(cols):\\\\n                for j, val3 in enumerate(ch):\\\\n                    # Assuming you want to store the pair as tuples in the matrix\\\\n                    frame[i, j, k] = image[val1, val2, val3]\\\\n\\\\n        out.write(np.array(frame))\\\\n\\\\nwith a simple numpy function without using for loop', id='cc1505b5-edf0-46d4-84a1-735608fc29d1')]\\n            AI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:OllamaFunctions] [17.31s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-abbe29ca-3ccc-484c-9205-17e08213b6de-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"test_code\",\n",
      "                \"args\": {\n",
      "                  \"prefix\": \"Vectorizing a function using numpy\",\n",
      "                  \"imports\": \"import numpy as np\\nfrom PIL import Image\",\n",
      "                  \"code\": \"def vectorize(image, rows, cols, ch):\\n    out_h = len(rows)\\n    out_w = len(cols)\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\n    for i, val1 in enumerate(rows):\\n        for j, val2 in enumerate(cols):\\n            for j, val3 in enumerate(ch):\\n                # Assuming you want to store the pair as tuples in the matrix\\n                frame[i, j, k] = image[val1, val2, val3]\\n    return frame\",\n",
      "                  \"test\": \"image = Image.open('path/to/image.jpg')\\nrows = [0, 1, 2, 3, 4]\\ncols = [5, 6, 7, 8, 9]\\nch = [10, 11, 12, 13, 14]\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\n\\nframe = vectorize(image, rows, cols, ch)\\n\\nassert frame.shape == (5, 5, 3)\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\nassert np.allclose(frame[4, 4], image[4, 9, 14])\"\n",
      "                },\n",
      "                \"id\": \"call_f9af304e532b4eeb8fb2602964e28c44\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > chain:parse_response] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > chain:parse_response] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"{\\\"prefix\\\": \\\"Vectorizing a function using numpy\\\", \\\"imports\\\": \\\"import numpy as np\\\\nfrom PIL import Image\\\", \\\"code\\\": \\\"def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", \\\"test\\\": \\\"image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14])\\\"}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"{\\\"prefix\\\": \\\"Vectorizing a function using numpy\\\", \\\"imports\\\": \\\"import numpy as np\\\\nfrom PIL import Image\\\", \\\"code\\\": \\\"def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", \\\"test\\\": \\\"image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14])\\\"}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:PydanticOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [17.31s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,error,messages,generation,iterations>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,error,messages,generation,iterations>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [17.31s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is my attempt to solve the problem: Vectorizing a function using numpy \n",
      " Imports: import numpy as np\n",
      "from PIL import Image \n",
      " Test: image = Image.open('path/to/image.jpg')\n",
      "rows = [0, 1, 2, 3, 4]\n",
      "cols = [5, 6, 7, 8, 9]\n",
      "ch = [10, 11, 12, 13, 14]\n",
      "out = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\n",
      "\n",
      "frame = vectorize(image, rows, cols, ch)\n",
      "\n",
      "assert frame.shape == (5, 5, 3)\n",
      "assert np.allclose(frame[0, 0], image[0, 5, 10])\n",
      "assert np.allclose(frame[4, 4], image[4, 9, 14]) \n",
      " Code: def vectorize(image, rows, cols, ch):\n",
      "    out_h = len(rows)\n",
      "    out_w = len(cols)\n",
      "    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\n",
      "    for i, val1 in enumerate(rows):\n",
      "        for j, val2 in enumerate(cols):\n",
      "            for j, val3 in enumerate(ch):\n",
      "                # Assuming you want to store the pair as tuples in the matrix\n",
      "                frame[i, j, k] = image[val1, val2, val3]\n",
      "    return frame\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<check_code,error,messages,generation,iterations>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<check_code,error,messages,generation,iterations>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:decide_to_finish] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---DECISION: RE-TRY SOLUTION---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:decide_to_finish] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"generate\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<branch:check_code:decide_to_finish:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<branch:check_code:decide_to_finish:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code] [2ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Your solution failed the code execution test or unit test: [Errno 2] No such file or directory: '/home/dmovchan/Desktop/building/local-agent/path/to/image.jpg') Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a coding assistant. Ensure any code or test you provide can be executed with all required imports and variables \\n\\n            defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the tests to check corectness of your solution and invocation of these tests, 4) the functioning code block.\\n            \\n Human: [HumanMessage(content='I want to vectorize a function\\\\n\\\\n        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n        for i, val1 in enumerate(rows):\\\\n            for j, val2 in enumerate(cols):\\\\n                for j, val3 in enumerate(ch):\\\\n                    # Assuming you want to store the pair as tuples in the matrix\\\\n                    frame[i, j, k] = image[val1, val2, val3]\\\\n\\\\n        out.write(np.array(frame))\\\\n\\\\nwith a simple numpy function without using for loop', id='cc1505b5-edf0-46d4-84a1-735608fc29d1'), AIMessage(content=\\\"Here is my attempt to solve the problem: Vectorizing a function using numpy \\\\n Imports: import numpy as np\\\\nfrom PIL import Image \\\\n Test: image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14]) \\\\n Code: def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", id='08014208-d944-4bd6-b42b-b926715bc7b6'), AIMessage(content=\\\"Here is my attempt to solve the problem: Vectorizing a function using numpy \\\\n Imports: import numpy as np\\\\nfrom PIL import Image \\\\n Test: image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14]) \\\\n Code: def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", id='48ce70e1-d040-468c-aa0a-6dbc465d8495'), HumanMessage(content=\\\"Your solution failed the code execution test or unit test: [Errno 2] No such file or directory: '/home/dmovchan/Desktop/building/local-agent/path/to/image.jpg') Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\\\", id='57b721ba-a848-46a6-b200-4ea03bd8b0d9'), HumanMessage(content=\\\"Your solution failed the code execution test or unit test: [Errno 2] No such file or directory: '/home/dmovchan/Desktop/building/local-agent/path/to/image.jpg') Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\\\", id='9bd5bfd2-a87d-41c5-b47d-7eff62f46209')]\\n            AI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:OllamaFunctions] [20.05s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"\",\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run-1ff4acd3-a44d-4bcb-b2eb-a6266308ca27-0\",\n",
      "            \"tool_calls\": [\n",
      "              {\n",
      "                \"name\": \"test_code\",\n",
      "                \"args\": {\n",
      "                  \"prefix\": \"Vectorizing a function using numpy\",\n",
      "                  \"imports\": \"import numpy as np\\nfrom PIL import Image\",\n",
      "                  \"code\": \"def vectorize(image, rows, cols, ch):\\n    out_h = len(rows)\\n    out_w = len(cols)\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\n    for i, val1 in enumerate(rows):\\n        for j, val2 in enumerate(cols):\\n            for j, val3 in enumerate(ch):\\n                # Assuming you want to store the pair as tuples in the matrix\\n                frame[i, j, k] = image[val1, val2, val3]\\n    return frame\",\n",
      "                  \"test\": \"image = Image.open('path/to/image.jpg')\\nrows = [0, 1, 2, 3, 4]\\ncols = [5, 6, 7, 8, 9]\\nch = [10, 11, 12, 13, 14]\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\n\\nframe = vectorize(image, rows, cols, ch)\\n\\nassert frame.shape == (5, 5, 3)\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\nassert np.allclose(frame[4, 4], image[4, 9, 14])\"\n",
      "                },\n",
      "                \"id\": \"call_800d0b875fb047d4badfb26e9dae2267\"\n",
      "              }\n",
      "            ],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > chain:parse_response] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > chain:parse_response] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"{\\\"prefix\\\": \\\"Vectorizing a function using numpy\\\", \\\"imports\\\": \\\"import numpy as np\\\\nfrom PIL import Image\\\", \\\"code\\\": \\\"def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", \\\"test\\\": \\\"image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14])\\\"}\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:PydanticOutputParser] Entering Parser run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"{\\\"prefix\\\": \\\"Vectorizing a function using numpy\\\", \\\"imports\\\": \\\"import numpy as np\\\\nfrom PIL import Image\\\", \\\"code\\\": \\\"def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", \\\"test\\\": \\\"image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14])\\\"}\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > parser:PydanticOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [20.05s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,error,messages,generation,iterations>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:ChannelWrite<generate,error,messages,generation,iterations>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [20.05s] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here is my attempt to solve the problem: Vectorizing a function using numpy \n",
      " Imports: import numpy as np\n",
      "from PIL import Image \n",
      " Test: image = Image.open('path/to/image.jpg')\n",
      "rows = [0, 1, 2, 3, 4]\n",
      "cols = [5, 6, 7, 8, 9]\n",
      "ch = [10, 11, 12, 13, 14]\n",
      "out = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\n",
      "\n",
      "frame = vectorize(image, rows, cols, ch)\n",
      "\n",
      "assert frame.shape == (5, 5, 3)\n",
      "assert np.allclose(frame[0, 0], image[0, 5, 10])\n",
      "assert np.allclose(frame[4, 4], image[4, 9, 14]) \n",
      " Code: def vectorize(image, rows, cols, ch):\n",
      "    out_h = len(rows)\n",
      "    out_w = len(cols)\n",
      "    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\n",
      "    for i, val1 in enumerate(rows):\n",
      "        for j, val2 in enumerate(cols):\n",
      "            for j, val3 in enumerate(ch):\n",
      "                # Assuming you want to store the pair as tuples in the matrix\n",
      "                frame[i, j, k] = image[val1, val2, val3]\n",
      "    return frame\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<check_code,error,messages,generation,iterations>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<check_code,error,messages,generation,iterations>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:decide_to_finish] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---DECISION: RE-TRY SOLUTION---\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:decide_to_finish] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output\": \"generate\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<branch:check_code:decide_to_finish:generate>] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code > chain:ChannelWrite<branch:check_code:decide_to_finish:generate>] [0ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:check_code] [1ms] Exiting Chain run with output:\n",
      "\u001b[0m[outputs]\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Your solution failed the code execution test or unit test: [Errno 2] No such file or directory: '/home/dmovchan/Desktop/building/local-agent/path/to/image.jpg') Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "---GENERATING CODE SOLUTION---\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] Entering Prompt run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > prompt:PromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001b[0m[outputs]\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:OllamaFunctions] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: You are a coding assistant. Ensure any code or test you provide can be executed with all required imports and variables \\n\\n            defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the tests to check corectness of your solution and invocation of these tests, 4) the functioning code block.\\n            \\n Human: [HumanMessage(content='I want to vectorize a function\\\\n\\\\n        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n        for i, val1 in enumerate(rows):\\\\n            for j, val2 in enumerate(cols):\\\\n                for j, val3 in enumerate(ch):\\\\n                    # Assuming you want to store the pair as tuples in the matrix\\\\n                    frame[i, j, k] = image[val1, val2, val3]\\\\n\\\\n        out.write(np.array(frame))\\\\n\\\\nwith a simple numpy function without using for loop', id='cc1505b5-edf0-46d4-84a1-735608fc29d1'), AIMessage(content=\\\"Here is my attempt to solve the problem: Vectorizing a function using numpy \\\\n Imports: import numpy as np\\\\nfrom PIL import Image \\\\n Test: image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14]) \\\\n Code: def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", id='08014208-d944-4bd6-b42b-b926715bc7b6'), AIMessage(content=\\\"Here is my attempt to solve the problem: Vectorizing a function using numpy \\\\n Imports: import numpy as np\\\\nfrom PIL import Image \\\\n Test: image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14]) \\\\n Code: def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", id='48ce70e1-d040-468c-aa0a-6dbc465d8495'), HumanMessage(content=\\\"Your solution failed the code execution test or unit test: [Errno 2] No such file or directory: '/home/dmovchan/Desktop/building/local-agent/path/to/image.jpg') Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\\\", id='57b721ba-a848-46a6-b200-4ea03bd8b0d9'), HumanMessage(content=\\\"Your solution failed the code execution test or unit test: [Errno 2] No such file or directory: '/home/dmovchan/Desktop/building/local-agent/path/to/image.jpg') Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\\\", id='9bd5bfd2-a87d-41c5-b47d-7eff62f46209'), AIMessage(content=\\\"Here is my attempt to solve the problem: Vectorizing a function using numpy \\\\n Imports: import numpy as np\\\\nfrom PIL import Image \\\\n Test: image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14]) \\\\n Code: def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", id='075ac069-80c5-45b5-96b2-52848a6c1982'), AIMessage(content=\\\"Here is my attempt to solve the problem: Vectorizing a function using numpy \\\\n Imports: import numpy as np\\\\nfrom PIL import Image \\\\n Test: image = Image.open('path/to/image.jpg')\\\\nrows = [0, 1, 2, 3, 4]\\\\ncols = [5, 6, 7, 8, 9]\\\\nch = [10, 11, 12, 13, 14]\\\\nout = Image.new('RGB', (len(rows), len(cols)), color=(0, 0, 0))\\\\n\\\\nframe = vectorize(image, rows, cols, ch)\\\\n\\\\nassert frame.shape == (5, 5, 3)\\\\nassert np.allclose(frame[0, 0], image[0, 5, 10])\\\\nassert np.allclose(frame[4, 4], image[4, 9, 14]) \\\\n Code: def vectorize(image, rows, cols, ch):\\\\n    out_h = len(rows)\\\\n    out_w = len(cols)\\\\n    frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\\\\n    for i, val1 in enumerate(rows):\\\\n        for j, val2 in enumerate(cols):\\\\n            for j, val3 in enumerate(ch):\\\\n                # Assuming you want to store the pair as tuples in the matrix\\\\n                frame[i, j, k] = image[val1, val2, val3]\\\\n    return frame\\\", id='4d8f064c-d12e-48a2-9ad4-6a88b4d0ea99'), HumanMessage(content=\\\"Your solution failed the code execution test or unit test: [Errno 2] No such file or directory: '/home/dmovchan/Desktop/building/local-agent/path/to/image.jpg') Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\\\", id='7af3ee7a-6e81-46fb-993a-e1aa13e19beb'), HumanMessage(content=\\\"Your solution failed the code execution test or unit test: [Errno 2] No such file or directory: '/home/dmovchan/Desktop/building/local-agent/path/to/image.jpg') Reflect on this error and your prior attempt to solve the problem. (1) State what you think went wrong with the prior solution and (2) try to solve this problem again. Return the FULL SOLUTION. Use the code tool to structure the output with a prefix, imports, test and code block:\\\", id='5225e73f-d763-4e32-bd35-00ffcfb12e33')]\\n            AI:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[31;1m\u001b[1;3m[llm/error]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence > llm:OllamaFunctions] [19.82s] LLM run errored with error:\n",
      "\u001b[0m\"KeyError('tool')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 446, in generate\\n    self._generate_with_cache(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 671, in _generate_with_cache\\n    result = self._generate(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_experimental/llms/ollama_functions.py\\\", line 323, in _generate\\n    called_tool_name = parsed_chat_result[\\\"tool\\\"]\\n\\n\\nKeyError: 'tool'\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate > chain:RunnableSequence] [19.82s] Chain run errored with error:\n",
      "\u001b[0m\"KeyError('tool')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 2495, in invoke\\n    input = step.invoke(input, config)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 4558, in invoke\\n    return self.bound.invoke(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 170, in invoke\\n    self.generate_prompt(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 599, in generate_prompt\\n    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 456, in generate\\n    raise e\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 446, in generate\\n    self._generate_with_cache(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 671, in _generate_with_cache\\n    result = self._generate(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_experimental/llms/ollama_functions.py\\\", line 323, in _generate\\n    called_tool_name = parsed_chat_result[\\\"tool\\\"]\\n\\n\\nKeyError: 'tool'\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:LangGraph > chain:generate] [19.82s] Chain run errored with error:\n",
      "\u001b[0m\"KeyError('tool')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 2493, in invoke\\n    input = step.invoke(input, config, **kwargs)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/utils.py\\\", line 95, in invoke\\n    ret = context.run(self.func, input, **kwargs)\\n\\n\\n  File \\\"/tmp/ipykernel_30405/3163946185.py\\\", line 29, in generate\\n    code_solution = combined_chain.invoke(messages)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 2495, in invoke\\n    input = step.invoke(input, config)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 4558, in invoke\\n    return self.bound.invoke(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 170, in invoke\\n    self.generate_prompt(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 599, in generate_prompt\\n    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 456, in generate\\n    raise e\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 446, in generate\\n    self._generate_with_cache(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 671, in _generate_with_cache\\n    result = self._generate(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_experimental/llms/ollama_functions.py\\\", line 323, in _generate\\n    called_tool_name = parsed_chat_result[\\\"tool\\\"]\\n\\n\\nKeyError: 'tool'\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[chain:LangGraph] [57.20s] Chain run errored with error:\n",
      "\u001b[0m\"KeyError('tool')Traceback (most recent call last):\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/pregel/__init__.py\\\", line 963, in stream\\n    _panic_or_proceed(done, inflight, step)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/pregel/__init__.py\\\", line 1489, in _panic_or_proceed\\n    raise exc\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/concurrent/futures/thread.py\\\", line 58, in run\\n    result = self.fn(*self.args, **self.kwargs)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/pregel/retry.py\\\", line 66, in run_with_retry\\n    task.proc.invoke(task.input, task.config)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 2493, in invoke\\n    input = step.invoke(input, config, **kwargs)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/utils.py\\\", line 95, in invoke\\n    ret = context.run(self.func, input, **kwargs)\\n\\n\\n  File \\\"/tmp/ipykernel_30405/3163946185.py\\\", line 29, in generate\\n    code_solution = combined_chain.invoke(messages)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 2495, in invoke\\n    input = step.invoke(input, config)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py\\\", line 4558, in invoke\\n    return self.bound.invoke(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 170, in invoke\\n    self.generate_prompt(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 599, in generate_prompt\\n    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 456, in generate\\n    raise e\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 446, in generate\\n    self._generate_with_cache(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py\\\", line 671, in _generate_with_cache\\n    result = self._generate(\\n\\n\\n  File \\\"/home/dmovchan/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_experimental/llms/ollama_functions.py\\\", line 323, in _generate\\n    called_tool_name = parsed_chat_result[\\\"tool\\\"]\\n\\n\\nKeyError: 'tool'\"\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'tool'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 26\u001b[0m\n\u001b[1;32m     10\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'''\u001b[39m\u001b[38;5;124mI want to vectorize a function\u001b[39m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;124m        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \n\u001b[1;32m     21\u001b[0m \u001b[38;5;124mwith a simple numpy function without using for loop\u001b[39m\u001b[38;5;124m'''\u001b[39m\n\u001b[1;32m     23\u001b[0m events \u001b[38;5;241m=\u001b[39m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m     24\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, question)], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miterations\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m}, config, stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[1;32m     27\u001b[0m     _print_event(event, _printed)\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/pregel/__init__.py:963\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, input_keys, interrupt_before, interrupt_after, debug)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m fut, task\n\u001b[1;32m    962\u001b[0m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[0;32m--> 963\u001b[0m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minflight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# don't keep futures around in memory longer than needed\u001b[39;00m\n\u001b[1;32m    965\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m done, inflight, futures\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/pregel/__init__.py:1489\u001b[0m, in \u001b[0;36m_panic_or_proceed\u001b[0;34m(done, inflight, step)\u001b[0m\n\u001b[1;32m   1487\u001b[0m             inflight\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mcancel()\n\u001b[1;32m   1488\u001b[0m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[0;32m-> 1489\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[1;32m   1492\u001b[0m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[1;32m   1493\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[1;32m   1494\u001b[0m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/pregel/retry.py:66\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy)\u001b[0m\n\u001b[1;32m     64\u001b[0m task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# if successful, end\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py:2493\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2489\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m   2490\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2491\u001b[0m )\n\u001b[1;32m   2492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2493\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2495\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langgraph/utils.py:95\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m accepts_config(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc):\n\u001b[1;32m     94\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\n\u001b[0;32m---> 95\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[0;32mIn[28], line 29\u001b[0m, in \u001b[0;36mgenerate\u001b[0;34m(state)\u001b[0m\n\u001b[1;32m     26\u001b[0m error \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Solution\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m code_solution \u001b[38;5;241m=\u001b[39m \u001b[43mcombined_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m messages \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m     (\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistant\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     33\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHere is my attempt to solve the problem: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode_solution\u001b[38;5;241m.\u001b[39mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Imports: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode_solution\u001b[38;5;241m.\u001b[39mimports\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Test: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode_solution\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m Code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcode_solution\u001b[38;5;241m.\u001b[39mcode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     34\u001b[0m     )\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Increment\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py:2495\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   2494\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2495\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2496\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/runnables/base.py:4558\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   4552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   4553\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4554\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   4555\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4556\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   4557\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 4558\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4559\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4560\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4561\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:170\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    166\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    167\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    169\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 170\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    180\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:599\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    593\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    597\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    598\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 599\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:456\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    455\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 456\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    457\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    458\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    460\u001b[0m ]\n\u001b[1;32m    461\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:446\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 446\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m         )\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    454\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:671\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 671\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/local_agent/lib/python3.10/site-packages/langchain_experimental/llms/ollama_functions.py:323\u001b[0m, in \u001b[0;36mOllamaFunctions._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m did not respond with valid JSON. \u001b[39m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124m        Please try again. \u001b[39m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;124m        Response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchat_generation_content\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 323\u001b[0m called_tool_name \u001b[38;5;241m=\u001b[39m \u001b[43mparsed_chat_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    324\u001b[0m called_tool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m    325\u001b[0m     (fn \u001b[38;5;28;01mfor\u001b[39;00m fn \u001b[38;5;129;01min\u001b[39;00m functions \u001b[38;5;28;01mif\u001b[39;00m fn[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m called_tool_name), \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m called_tool \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'tool'"
     ]
    }
   ],
   "source": [
    "_printed = set()\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "question = '''I want to vectorize a function\n",
    "\n",
    "        frame = np.zeros((out_h, out_w, 3), dtype=np.uint8)\n",
    "        for i, val1 in enumerate(rows):\n",
    "            for j, val2 in enumerate(cols):\n",
    "                for j, val3 in enumerate(ch):\n",
    "                    # Assuming you want to store the pair as tuples in the matrix\n",
    "                    frame[i, j, k] = image[val1, val2, val3]\n",
    "\n",
    "        out.write(np.array(frame))\n",
    "\n",
    "with a simple numpy function without using for loop'''\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", question)], \"iterations\": 0}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a3292-1e0e-49cf-8b28-bef179afe6a2",
   "metadata": {},
   "source": [
    "Trace w/ good example of self-correction:\n",
    "\n",
    "https://smith.langchain.com/public/b54778a0-d267-4f09-bc28-71761201c522/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee05da1f-c272-405d-8a7b-552cfc3106e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_printed = set()\n",
    "thread_id = str(uuid.uuid4())\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "question = \"\"\"Create a Python program that allows two players to play a game of Tic-Tac-Toe. The game should be played on a 3x3 grid. The program should:\n",
    "\n",
    "- Allow players to take turns to input their moves.\n",
    "- Check for invalid moves (e.g., placing a marker on an already occupied space).\n",
    "- Determine and announce the winner or if the game ends in a draw.\n",
    "\n",
    "Requirements:\n",
    "- Use a 2D list to represent the Tic-Tac-Toe board.\n",
    "- Use functions to modularize the code.\n",
    "- Validate player input.\n",
    "- Check for win conditions and draw conditions after each move.\"\"\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", question)], \"iterations\": 0}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d900cd6-2df9-467d-8e74-803527269008",
   "metadata": {},
   "source": [
    "Trace w/ good example of failure to correct:\n",
    "\n",
    "https://smith.langchain.com/public/871ae736-2f77-44d4-b0da-a600d8f5377d/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814fc2a4-8e5b-4faa-8f52-3977226bd09a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a093a5-7302-4f86-8d4c-625d079e44e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567ea81-f277-4402-a17e-25c628c7273c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
